{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTjcp3WzvTJN"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed, GPT2Tokenizer\n",
        "\n",
        "bert_model = \"bert-base-uncased\"\n",
        "roberta_model = \"roberta-base\"\n",
        "bart_model = \"facebook/bart-base\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk"
      ],
      "metadata": {
        "id": "3q5jpS4hvVk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"unit 1.txt\"\n",
        "\n",
        "try:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "    print(\"File loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: '{file_path}' not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWnT6rqFvWcp",
        "outputId": "e7ec1bdf-6aa4-46cb-ccb4-fd356a312ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "# Suppress warnings/logs\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "prompt = \"The future of Artificial Intelligence is\"\n",
        "\n",
        "def safe_generate(model_name, label):\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=model_name)\n",
        "        output = generator(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
        "        print(f\"{label} Output:\\n{output[0]['generated_text']}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"{label} Error: {e}\\n\")\n",
        "\n",
        "# 1. BERT\n",
        "safe_generate(\"bert-base-uncased\", \"BERT\")\n",
        "\n",
        "# 2. RoBERTa\n",
        "safe_generate(\"roberta-base\", \"RoBERTa\")\n",
        "\n",
        "# 3. BART\n",
        "safe_generate(\"facebook/bart-base\", \"BART\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8JoocXPvwDh",
        "outputId": "fd795aa4-1d7f-4df2-e428-ec366f22ef01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Output:\n",
            "The future of Artificial Intelligence is................................................................................................................................................................................................................................................................\n",
            "\n",
            "RoBERTa Output:\n",
            "The future of Artificial Intelligence is\n",
            "\n",
            "BART Output:\n",
            "The future of Artificial Intelligence isOtherwise ShakOtherwise sure Shak Shak323208 df empir squat Shak chuckms healer df MarxismOtherwisePatrick Walkdy Shak slipsreleased df df32 slips debugger Walk slips Shak denim Shak df df df Walk Drawn Drawn Drawn 361 slipsino Person Princeton Shak chuckSpoilerSpoiler slips df df initially dismant Drawn Crkas Drawn Drawn spotsenc Shak Drawn Drawnino Drawn Drawn opposition Shak workload slips Shak slips df Drawn DrawnEngland Drawn32 Drawn DrawnSel Drawn workload Drawn Drawn Output Drawn Drawn communism Drawn Drawn debugger spots spots dfPost df df workload Drawn df Drawn dfJe Drawn DrawnaxeFrames df kingdoms df Drawnlein Drawn Drawn slips Drawn Drawneller Drawn Drawn df spots spots game Drawn Drawn LT Drawn Drawn Alvin Drawn origins sure Drawn Drawnaze spots Drawn Drawn princip Drawn gameStatus Alvin df df Alvin df impacting impacting spots spotsaily princip futures df principAlert skysc df spots principStatus Drawn Drawn Beet Drawn skysc Alvin df game sure Alvin workloadStatus Molecular princip debuggerkaskasFramesFrames Drawn Drawn origins df df princip Drawn DrawnwalkingFrameskas workload Drawnkasbreak Drawn Drawn2014 Hook df Drawnkas tables df Beet game df Drawn skysc Drawn debuggerkas spots Drawnaxekas impactingkaskas Beet20142014kas debugger impacting df df futures debuggerAlert originskas originskaskas df debugger skysckas Beet Beet debugger spots df elephants df df game game\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import warnings, logging\n",
        "\n",
        "# Suppress warnings/logs\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# Sentences with correct mask tokens\n",
        "sentences = {\n",
        "    \"bert-base-uncased\": \"The goal of Generative AI is to [MASK] new content.\",\n",
        "    \"roberta-base\": \"The goal of Generative AI is to <mask> new content.\",\n",
        "    \"facebook/bart-base\": \"The goal of Generative AI is to <mask> new content.\"\n",
        "}\n",
        "\n",
        "models = [\"bert-base-uncased\", \"roberta-base\", \"facebook/bart-base\"]\n",
        "\n",
        "for model in models:\n",
        "    try:\n",
        "        fill_mask = pipeline(\"fill-mask\", model=model)\n",
        "        results = fill_mask(sentences[model])\n",
        "\n",
        "        print(f\"\\nModel: {model}\")\n",
        "        print(\"Predictions:\")\n",
        "        for r in results:\n",
        "            print(f\"  - {r['sequence']} (score: {r['score']:.4f})\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nModel: {model}\")\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2POhKTxDwImk",
        "outputId": "477bc0eb-4b5b-471f-c9fc-8b50ce2579f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: bert-base-uncased\n",
            "Predictions:\n",
            "  - the goal of generative ai is to create new content. (score: 0.5397)\n",
            "  - the goal of generative ai is to generate new content. (score: 0.1558)\n",
            "  - the goal of generative ai is to produce new content. (score: 0.0541)\n",
            "  - the goal of generative ai is to develop new content. (score: 0.0445)\n",
            "  - the goal of generative ai is to add new content. (score: 0.0176)\n",
            "\n",
            "Model: roberta-base\n",
            "Predictions:\n",
            "  - The goal of Generative AI is to generate new content. (score: 0.3711)\n",
            "  - The goal of Generative AI is to create new content. (score: 0.3677)\n",
            "  - The goal of Generative AI is to discover new content. (score: 0.0835)\n",
            "  - The goal of Generative AI is to find new content. (score: 0.0213)\n",
            "  - The goal of Generative AI is to provide new content. (score: 0.0165)\n",
            "\n",
            "Model: facebook/bart-base\n",
            "Predictions:\n",
            "  - The goal of Generative AI is to create new content. (score: 0.0746)\n",
            "  - The goal of Generative AI is to help new content. (score: 0.0657)\n",
            "  - The goal of Generative AI is to provide new content. (score: 0.0609)\n",
            "  - The goal of Generative AI is to enable new content. (score: 0.0359)\n",
            "  - The goal of Generative AI is to improve new content. (score: 0.0332)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import warnings, logging\n",
        "\n",
        "# Suppress warnings/logs\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "context = \"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
        "question = \"What are the risks?\"\n",
        "\n",
        "models = [\"bert-base-uncased\", \"roberta-base\", \"facebook/bart-base\"]\n",
        "\n",
        "for model in models:\n",
        "    try:\n",
        "        qa = pipeline(\"question-answering\", model=model)\n",
        "        print(f\"\\nModel: {model}\")\n",
        "        print(qa(question=question, context=context))\n",
        "    except Exception as e:\n",
        "        print(f\"\\nModel: {model} FAILED\")\n",
        "        print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU-F2Jc6zsoA",
        "outputId": "1834c475-2bec-4500-f547-68577aee8759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: bert-base-uncased\n",
            "{'score': 0.008281194604933262, 'start': 72, 'end': 81, 'answer': 'deepfakes'}\n",
            "\n",
            "Model: roberta-base\n",
            "{'score': 0.004184452351182699, 'start': 0, 'end': 81, 'answer': 'Generative AI poses significant risks such as hallucinations, bias, and deepfakes'}\n",
            "\n",
            "Model: facebook/bart-base\n",
            "{'score': 0.028195755556225777, 'start': 11, 'end': 71, 'answer': 'AI poses significant risks such as hallucinations, bias, and'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation Table\n",
        "\n",
        "| Task       | Model   | Classification (Success/Failure) | Observation (What actually happened?)                                   | Why did this happen? (Architectural Reason)                  |\n",
        "|------------|---------|----------------------------------|------------------------------------------------------------------------|---------------------------------------------------------------|\n",
        "| Generation | BERT    | Failure                          | Output was just dots, no real text.                                    | BERT is only an encoder, not built to write sentences.        |\n",
        "|            | RoBERTa | Failure                          | Output stopped after the prompt, no continuation.                      | RoBERTa is also only an encoder, not made for text generation.|\n",
        "|            | BART    | Partial Success                  | Output was messy and random words.                                     | BART base is not trained for generation tasks.                |\n",
        "| Fill-Mask  | BERT    | Success                          | Predicted clear words like 'create', 'generate', 'produce'.            | BERT is trained to guess missing words (MLM).                 |\n",
        "|            | RoBERTa | Success                          | Predicted good words like 'generate', 'create', 'discover'.            | RoBERTa is trained for masked word prediction.                |\n",
        "|            | BART    | Success                          | Predicted words like 'create', 'help', 'provide', but less accurate.   | BART can do MLM but it is not its main training goal.         |\n",
        "| QA         | BERT    | Failure                          | Answered only 'deepfakes' with very low score.                         | Base BERT is not trained for question answering.              |\n",
        "|            | RoBERTa | Partial Success                  | Gave the whole context as answer, but not precise.                     | RoBERTa base is not fine-tuned for QA tasks.                  |\n",
        "|            | BART    | Failure                          | Answer was a broken sentence fragment.                                 | BART base is not trained for QA span extraction.              |"
      ],
      "metadata": {
        "id": "ogns9mUG1gt2"
      }
    }
  ]
}